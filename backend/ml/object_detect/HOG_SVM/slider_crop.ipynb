{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2073fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage import data, draw, io, img_as_ubyte\n",
    "from skimage.feature import hog\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy as np \n",
    "\n",
    "from features import FeaturesRGB\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ca796",
   "metadata": {},
   "source": [
    "### Classifier that stores the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a530f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier:\n",
    "\n",
    "    def __init__(self, svc, scaler):\n",
    "        self.svc = svc\n",
    "        self.scaler = scaler \n",
    "\n",
    "    def predict(self, f):\n",
    "        f = self.scaler.transform([f])\n",
    "        r = self.svc.predict(f)\n",
    "        return int(r[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93f08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slider:\n",
    "    \n",
    "    def __init__(self, frame, classifier, hog_params):\n",
    "        self.frame = frame\n",
    "        self.classifier = classifier\n",
    "        self.hog_params = hog_params\n",
    "        self.bd_box = hog_params['bounding_box_size']\n",
    "\n",
    "    def stripping(self, pad, start_pos_x, start_pos_y):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.start_pos_x = start_pos_x\n",
    "        self.start_pos_y = start_pos_y\n",
    "        \n",
    "        pad_h =  self.bd_box[0] + pad * 2\n",
    "        pad_w =  self.bd_box[1] + pad * 2\n",
    "        \n",
    "        #crop the LFT area\n",
    "        strip = self.frame[start_pos_y :self.frame.shape[0] - start_pos_y,\\\n",
    "                                start_pos_x: self.frame.shape[1] - start_pos_x, :]\n",
    "        \n",
    "        #resize \n",
    "        self.scale_factor = self.frame.shape[0] / pad_h\n",
    "        self.strip_resized = resize(strip, (int(strip.shape[0] / self.scale_factor), \\\n",
    "                                            int(strip.shape[1] / self.scale_factor)), \\\n",
    "                                            anti_aliasing=True)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def sliding(self, increment):\n",
    "        \n",
    "        box = []\n",
    "        \n",
    "        ftrRGB = FeaturesRGB(self.hog_params)\n",
    "        \n",
    "        x_win_cnt = ( (self.strip_resized.shape[1] - self.bd_box[1]) // increment )\n",
    "        y_win_cnt = ( (self.strip_resized.shape[0] - self.bd_box[0]) // increment )\n",
    "        \n",
    "        #print(\"number of window: \", x_win_cnt, y_win_cnt)\n",
    "        \n",
    "        \n",
    "        for x_i in range(0, x_win_cnt):\n",
    "            for y_i in range(0, y_win_cnt):\n",
    "                strip_crop = self.strip_resized[y_i * increment : y_i * increment + self.bd_box[0],\\\n",
    "                                                x_i * increment : x_i * increment + self.bd_box[1], :]\n",
    "                #print(\"strip_crop: \", strip_crop.shape)\n",
    "                \n",
    "                hog_flatten = ftrRGB.cal_hog(strip_crop, 0)\n",
    "                \n",
    "                cls_rslt = self.classifier.predict(hog_flatten)\n",
    "                #print(\"result: \", cls_rslt)\n",
    "                \n",
    "                if cls_rslt:\n",
    "                    tmp_y = (y_i * increment) * self.scale_factor + self.start_pos_y\n",
    "                    tmp_x = (x_i * increment) * self.scale_factor + self.start_pos_x\n",
    "                    \n",
    "                    tmp_y_end = (y_i * increment + self.bd_box[0]) * self.scale_factor + self.start_pos_y\n",
    "                    tmp_x_end = (x_i * increment + self.bd_box[1]) * self.scale_factor + self.start_pos_x\n",
    "                    \n",
    "                    \n",
    "                    box.append((int(tmp_y), int(tmp_x), \\\n",
    "                                int(tmp_y_end), int(tmp_x_end)))\n",
    "                    \n",
    "                    \n",
    "                    #fig, ax = plt.subplots(1,1, figsize=(10, 5))\n",
    "                    #ax.title.set_text('strip_crop')\n",
    "                    #ax.imshow(strip_crop);\n",
    "        \n",
    "        return box\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901a104",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = joblib.load('../svc_validated.pkl')\n",
    "scaler = joblib.load('../scaler_validated.pkl')\n",
    "\n",
    "\n",
    "hog_params = {\n",
    "    'bounding_box_size': [384, 128],   \n",
    "    'orientations': 11, # number of bins\n",
    "    'pixels_per_cell': (8, 8), # normally (8,8), refers to 8x8 pixels are used to calculate hog\n",
    "    'cells_per_block': (2, 2),\n",
    "    'block_norm': 'L2-Hys'\n",
    "}\n",
    "\n",
    "\n",
    "cls = BinaryClassifier(svc, scaler)\n",
    "ftrRGB = FeaturesRGB(hog_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff36ce",
   "metadata": {},
   "source": [
    "### Getting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39558e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lft1_posit_path = glob.glob('../../mlft_classify/originals/negative/hcng/unchanged/*.jpg')\n",
    "\n",
    "lft1crop_posit_path = '../../mlft_classify/originals/negative/hcng/cropped/'\n",
    "lft1nochg_posit_path = '../../mlft_classify/originals/negative/hcng/unchanged/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f17311b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding: \" 12 \"...Finished, bounding box found?  False\n",
      "Sliding: \" 19 \"...Finished, bounding box found?  True\n",
      "Sliding: \" 20 \"...Finished, bounding box found?  False\n"
     ]
    }
   ],
   "source": [
    "slider_inc = 8\n",
    "\n",
    "for path in lft1_posit_path: \n",
    "    # Get file name\n",
    "    f_split = os.path.basename(path)\n",
    "    name_tmp = os.path.splitext(f_split)[0]\n",
    "    \n",
    "    lft_img = io.imread(path)\n",
    "    \n",
    "    #print(type(name_tmp), type(lft1nochg_posit_path))\n",
    "    \n",
    "    slider = Slider(lft_img, classifier = cls,  hog_params = hog_params)\n",
    "    slider.stripping(64, lft_img.shape[1] // 4, 32)\n",
    "    \n",
    "    \n",
    "    print(\"Sliding: \\\"\", name_tmp, \"\\\"...\", end='')\n",
    "    box = slider.sliding(slider_inc)\n",
    "    \n",
    "    print(\"Finished, bounding box found? \", (len(box) > 0))\n",
    "    \n",
    "    # crop image based on the bounding box\n",
    "    if len(box) > 0:\n",
    "        start_yx = box[0]\n",
    "        end_yx = box[-1]\n",
    "        \n",
    "        \n",
    "        v_pad = (start_yx[0] - end_yx[2]) // 4\n",
    "        h_pad = (start_yx[1] - end_yx[3]) // 6\n",
    "\n",
    "        strip = lft_img[start_yx[0] - v_pad : end_yx[2] + v_pad,\\\n",
    "                                    start_yx[1] - h_pad : end_yx[3] + h_pad, :]\n",
    "        \n",
    "        #strip1 = lft_img[start_yx[0]  : end_yx[2] ,\\\n",
    "                                    #start_yx[1]  : end_yx[3], :]\n",
    "            \n",
    "\n",
    "            \n",
    "        io.imsave(lft1crop_posit_path  + name_tmp + \"_cropped.jpg\", img_as_ubyte(strip))\n",
    "        \n",
    "        #fig, ax = plt.subplots(1,1, figsize=(20, 10))\n",
    "        #ax.imshow(strip)\n",
    "        #break\n",
    "    \n",
    "    else:\n",
    "        io.imsave(lft1nochg_posit_path  + name_tmp + \".jpg\", img_as_ubyte(lft_img))\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5552f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee769ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
